{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "CRSP_Compustat.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerryback/WRDS/blob/main/CRSP_Compustat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ],
      "metadata": {
        "id": "9ZAhurdxGkCk",
        "outputId": "6051457f-11cc-4c3d-e9cd-e576234e4438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and connect to WRDS"
      ],
      "metadata": {
        "id": "_LoCzT5GBd5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install wrds\n",
        "import wrds       \n",
        "conn = wrds.Connection() "
      ],
      "metadata": {
        "id": "x2jxPDcZA6vM",
        "outputId": "abaa37b9-6eed-4396-dac9-7fe8a19daab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from wrds) (1.4.31)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from wrds) (1.21.5)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from wrds) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->wrds) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->wrds) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->wrds) (4.11.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->wrds) (1.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->wrds) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->wrds) (3.10.0.2)\n",
            "Installing collected packages: psycopg2-binary, mock, wrds\n",
            "Successfully installed mock-4.0.3 psycopg2-binary-2.9.3 wrds-3.1.1\n",
            "Enter your WRDS username [root]:keback\n",
            "Enter your password:··········\n",
            "WRDS recommends setting up a .pgpass file.\n",
            "Create .pgpass file now [y/n]?: n\n",
            "You can create this file yourself at any time\n",
            "with the create_pgpass_file() function.\n",
            "Loading library list...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annual Compustat\n",
        "\n",
        "An example of pulling data from the annual Compustat table.  datadate is the end of the fiscal year.  We impose standard filters.  See https://wrds-web.wharton.upenn.edu/wrds/demo/demoform_compustat.cfm for a full list of Compustat variable definitions. Quarterly data is also available."
      ],
      "metadata": {
        "id": "Qd9Rv1GRM3MT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKo3oYPBJ72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f86b88-3de9-4ad1-8f47-a54c80b699e9"
      },
      "source": [
        "variables = ['txditc','pstkrv','pstkl','pstk','ceq','seq','at','lt','cogs','xsga','xint','sale','revt','mib']            \n",
        "\n",
        "start = '1963-01-01'\n",
        "\n",
        "variables = ', '.join(variables)\n",
        "df = conn.raw_sql(             \"SELECT a.gvkey, a.datadate, b.tic,\"\n",
        "                               + variables +\n",
        "                               \" from comp.FUNDA a left outer join comp.Names b \"\n",
        "                               \" on a.gvkey = b.gvkey \"\n",
        "                               \" where a.datadate >= '\" + start + \"' \"\n",
        "                               \" and INDFMT='INDL' and DATAFMT='STD' and POPSRC='D' and CONSOL='C' \"\n",
        "                               \" order by a.gvkey, datadate \", date_cols=['datadate'])\n",
        "df.gvkey = df.gvkey.astype(int)\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 526496 entries, 0 to 26495\n",
            "Data columns (total 17 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     526496 non-null  int64         \n",
            " 1   datadate  526496 non-null  datetime64[ns]\n",
            " 2   tic       526341 non-null  object        \n",
            " 3   txditc    411620 non-null  float64       \n",
            " 4   pstkrv    445051 non-null  float64       \n",
            " 5   pstkl     446644 non-null  float64       \n",
            " 6   pstk      449109 non-null  float64       \n",
            " 7   ceq       444380 non-null  float64       \n",
            " 8   seq       442918 non-null  float64       \n",
            " 9   at        448950 non-null  float64       \n",
            " 10  lt        446342 non-null  float64       \n",
            " 11  cogs      445403 non-null  float64       \n",
            " 12  xsga      359267 non-null  float64       \n",
            " 13  xint      400147 non-null  float64       \n",
            " 14  sale      447244 non-null  float64       \n",
            " 15  revt      447246 non-null  float64       \n",
            " 16  mib       432747 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(14), int64(1), object(1)\n",
            "memory usage: 72.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratios and growth rates\n",
        "\n",
        "Illustrate some standard types of calculations with Compustat data by computing some Fama-French characteristics."
      ],
      "metadata": {
        "id": "VwwEaLY1mxjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we shift fiscal-year-end data to the end of June in the next calendar year, to accommodate the reporting lag\n",
        "# this shift is standard for Fama and French\n",
        "\n",
        "df['date'] = pd.to_datetime(df.datadate.apply(lambda d: str(d.year+1)+'-06-30'))\n",
        "\n",
        "# sometimes a company changes its fiscal year and has two annual reports in the same calendar year\n",
        "# we keep the last annual report in this circumstace\n",
        "\n",
        "df = df.drop_duplicates(subset=['gvkey','date'],keep='last')  \n",
        "\n",
        "# the coalesce function implements the following logic:\n",
        "#   x = a if a exists\n",
        "#   else x = b if b exists\n",
        "#   else x = c if c exists\n",
        "#   ...\n",
        "# the dataframe that is input to the function should have columns in the following order:\n",
        "# first column = a (most desired definition)\n",
        "# second column = b (next most desired definition)\n",
        "# ... last column = least desired definition (used only if others do not exist)\n",
        "\n",
        "def coalesce(d) :\n",
        "    return d.bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "# Fama-French definition of book equity : shareholders equity + deferred taxes - preferred stock\n",
        "# Compustat has three preferred stock variables, we prefer pstkrv, then pstkl, then pstk\n",
        "# we prefer to use seq for shareholders equity, then ceq (common equity) + pstk, then total assets minus total liabilities\n",
        "# when adding pstk to ceq, we allow for pstk to be missing by filling nans with 0\n",
        "# we filter to observations with positive book equity\n",
        "\n",
        "deferredTaxes = df.txditc.fillna(0)    \n",
        "preferredStock = coalesce(df[['pstkrv','pstkl','pstk']]).fillna(0)                  \n",
        "seq2 = df.ceq + df.pstk.fillna(0)                \n",
        "seq3 = np.where((df['at']>=0) & (df['lt']>=0), df['at']-df['lt'], np.nan) \n",
        "seq3 = pd.Series(seq3, index=df.index)\n",
        "shareholdersEquity = coalesce(pd.concat((df.seq,seq2,seq3),axis=1))\n",
        "df['be'] = shareholdersEquity + deferredTaxes - preferredStock\n",
        "df = df[df.be>0]\n",
        "del deferredTaxes, preferredStock, seq2, seq3, shareholdersEquity\n",
        "\n",
        "# Fama-French definition of operating profitability: revenue - cost of goods sold - SG&A expenses - interest expense divided by equity\n",
        "\n",
        "costs = df.cogs.fillna(0) + df.xsga.fillna(0) + df.xint.fillna(0)\n",
        "sales = coalesce(df[['sale','revt']]) \n",
        "df['op'] = (sales-costs) / ( df.be + df.mib.fillna(0) )\n",
        "del costs, sales\n",
        "\n",
        "# Fama-French definition of investment: percent change in assets\n",
        "# we filter to observations with positive total assets\n",
        "# we group by gvkey whenever shifting or calculating changes to avoid errors at the point one firm's data ends and another starts\n",
        "\n",
        "df = df[df['at']>0]\n",
        "df['inv'] = df.groupby('gvkey')['at'].pct_change()\n",
        "\n",
        "# keep the variables we want to use\n",
        "\n",
        "df = df[['gvkey','date','datadate','be','op','inv']]\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "cXwB2fxbQ3kS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f04a15e-9a33-495c-e765-a9646ea24b7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 401998 entries, 1 to 26495\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     401998 non-null  int64         \n",
            " 1   date      401998 non-null  datetime64[ns]\n",
            " 2   datadate  401998 non-null  datetime64[ns]\n",
            " 3   be        401998 non-null  float64       \n",
            " 4   op        398892 non-null  float64       \n",
            " 5   inv       368228 non-null  float64       \n",
            "dtypes: datetime64[ns](2), float64(3), int64(1)\n",
            "memory usage: 21.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assign permnos \n",
        "\n",
        "Use the CRSP link table following instructions at WRDS."
      ],
      "metadata": {
        "id": "JRd3YRWgTZYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = conn.raw_sql(\" select distinct gvkey, lpermno as permno, linkdt, linkenddt \"\n",
        "                    \" from crsp.Ccmxpf_linktable \"\n",
        "                    \" where linktype in ('LU', 'LC') \"\n",
        "                    \" and LINKPRIM in ('P', 'C') \" )\n",
        "link['gvkey'] = link.gvkey.astype(int)\n",
        "link['permno'] = link.permno.astype(int)\n",
        "link['linkenddt'] = pd.to_datetime(link.linkenddt).fillna(pd.Timestamp('21000101'))\n",
        "df = df.merge(link,on='gvkey',how='inner')\n",
        "df = df[(df.datadate>=df.linkdt) & (df.datadate<=df.linkenddt)]\n",
        "df = df.drop(columns=['gvkey','datadate','linkdt','linkenddt'])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "5GwgshZLTVRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b650573-921f-4595-ba2c-50b91bc32ecb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 274403 entries, 6 to 407281\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype         \n",
            "---  ------  --------------   -----         \n",
            " 0   date    274403 non-null  datetime64[ns]\n",
            " 1   be      274403 non-null  float64       \n",
            " 2   op      273172 non-null  float64       \n",
            " 3   inv     264086 non-null  float64       \n",
            " 4   permno  274403 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
            "memory usage: 12.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRSP\n",
        "\n",
        "Get stock prices and returns from  CRSP (Center for Research in Security Prices).  There is both monthly and daily data.  See http://www.crsp.com/files/data_descriptions_guide_0.pdf for a complete set of variable definitions.  CRSP uses PERMCO as a permanent company identifier and PERMNO as a permanent security identifier.  Some companies have multiple classes of common stock, which means multiple common stock PERMNOs can be associated with a single PERMCO."
      ],
      "metadata": {
        "id": "X1bNXUw6T4xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = 'monthly'\n",
        "start = '1962-01-01'\n",
        "crsp_table = 'msf' if freq=='monthly' else 'dsf'\n",
        "     \n",
        "df2 = conn.raw_sql(\"SELECT a.permno, a.permco, a.date, a.ret, abs(a.prc)*a.shrout as me, b.exchcd, b.siccd, b.ticker \"\n",
        "                   \" from crsp.\" + crsp_table + \" a inner join crsp.msenames b \"\n",
        "                   \" on a.permno=b.permno and a.date between b.namedt and b.nameendt \"\n",
        "                   \" and b.exchcd in (1,2,3) and b.shrcd in (10,11) \"\n",
        "                   \" where a.date >= '\" + start + \"' \"\n",
        "                   \" order by a.date, a.permco, me \", date_cols=['date'])\n",
        "\n",
        "for col in ['permno','permco','exchcd'] :\n",
        "    df2[col] = df2[col].astype(int)\n",
        "\n",
        "# define market equity as sum of market equities of all permnos associated with a permco\n",
        "df2['me'] = df2.groupby(['date','permco']).me.transform(sum)\n",
        "\n",
        "# if there are multiple permnos for a permco, keep only the permno with largest market equity\n",
        "# this works because the sql query sorted by market equity within date/permco\n",
        "df2 = df2.drop_duplicates(subset=['date','permco'],keep='last')\n",
        "df2 = df2.drop(columns=['permco'])\n",
        "\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "VP7s-_6FRglI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720a143d-8fdf-4533-a990-93e0c7cc8c78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257644 entries, 0 to 291289\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(2), object(1)\n",
            "memory usage: 198.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define delisting returns\n",
        "\n",
        "This is always done, but there are some different ways to do it.  Here, we follow some of the literature and assign a lower delisting return to Nasdaq stocks than to NYSE/AMEX stocks if the delisting return is missing."
      ],
      "metadata": {
        "id": "9mCTmtbQQLVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = conn.raw_sql(\" select permno, dlret, dlstcd \" \n",
        "                   \" from crsp.mse \" \n",
        "                   \" where event='DELIST' and dlstcd>100 \"\n",
        "                   \" order by permno\")\n",
        "mse['permno'] = mse.permno.astype(int)\n",
        "df2 = df2.merge(mse, how='left', on='permno')\n",
        "del mse\n",
        "LastObs = df2.permno != df2.permno.shift(-1)                           # True if last date for stock\n",
        "DLCode = (df2.dlstcd==500) | ( (df2.dlstcd >=520)&(df2.dlstcd<=584) )  # True if delisted for poor performance\n",
        "\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & df2.exchcd.isin([1,2]), -0.35, df2.dlret )\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & (df2.exchcd==3), -0.55, df2.dlret )\n",
        "df2['dlret'] = np.where(df2.dlret.notnull() & df2.dlret<-1,-1,df2.dlret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.notnull(), (1+df2.ret)*(1+df2.dlret.fillna(0))-1, df2.ret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.isnull(), df2.dlret, df2.ret)\n",
        "df2 = df2.drop(columns=['dlstcd','dlret'])"
      ],
      "metadata": {
        "id": "hbc9Cedj56hg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Close WRDS\n",
        "\n",
        "You should close your WRDS connection when you have the data you need."
      ],
      "metadata": {
        "id": "andSngk7dYYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "IG450QBedW-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge CRSP with Compustat"
      ],
      "metadata": {
        "id": "Ot2qAYgwQyWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df2.merge(df, on = ['permno','date'], how='left')\n",
        "df.sort_values(by=['permno','date'],inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7c2-JEJvuv",
        "outputId": "b68679fe-826e-427f-a8b4-e66b08b2e8fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257655 entries, 1066070 to 3255333\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            " 7   be      float64       \n",
            " 8   op      float64       \n",
            " 9   inv     float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(2), object(1)\n",
            "memory usage: 273.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define size and book-to-market\n",
        "\n",
        "Fama and French use end-of-June market cap to define size each year (as of June 30).  They use end-of-prior-December market cap to define book-to-market on June 30.  "
      ],
      "metadata": {
        "id": "Oj6cH-wCY8qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "month = df.date.apply(lambda d: d.month)\n",
        "df['size'] = np.where(month==6, df.me, np.nan)\n",
        "df['bm'] = df.groupby('permno').apply(lambda d: d.be/d.me.shift(6)).values\n",
        "df['bm'] = np.where(month==6, df.bm, np.nan)\n",
        "df = df.drop(columns=['be'])"
      ],
      "metadata": {
        "id": "dtBuGlYqZH2V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill annual data into months\n",
        "\n",
        "Use the pandas ffill method to fill forward from Junes into successive months.  Occasionally firms change fiscal years, so filling for more than 12 months can be useful.  On the other hand, we don't want to fill forward if a permno exits the database for years and then returns, which happens occasionally (though rarely).  18 months is my arbitrary compromise."
      ],
      "metadata": {
        "id": "mKNaAI0pURK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['size','bm','op','inv']] = df.groupby('permno')[['size','bm','op','inv']].ffill(limit=18)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "353HWR6OKa4Q",
        "outputId": "10a4af0b-c7e5-4199-efeb-67b579f4c903"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257655 entries, 1066070 to 3255333\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            " 7   op      float64       \n",
            " 8   inv     float64       \n",
            " 9   size    float64       \n",
            " 10  bm      float64       \n",
            "dtypes: datetime64[ns](1), float64(7), int64(2), object(1)\n",
            "memory usage: 298.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fweL1rPCBJ8e"
      },
      "source": [
        "## Save Your Data\n",
        "\n",
        "The write and read commands to csv are as follows.  Here, we mount and save to google drive.\n",
        "\n",
        "    df.to_csv('/path/filename.csv')                                      # writes to disk  \n",
        "    df = pd.read_csv('/path/filename.csv', date_cols=['date'])           # reads from disk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLq29beCBJ8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804e584d-e361-48c1-d50a-5f7e5fa9b212"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df.to_csv('/content/drive/My Drive/crsp_compustat_example.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G8Ut-5xipF_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}