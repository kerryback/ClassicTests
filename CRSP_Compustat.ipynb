{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "CRSP_Compustat.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kerryback/Investments/blob/main/CRSP_Compustat.ipynb)"
      ],
      "metadata": {
        "id": "WLXzatrbGjuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ],
      "metadata": {
        "id": "9ZAhurdxGkCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and connect to WRDS"
      ],
      "metadata": {
        "id": "_LoCzT5GBd5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install wrds\n",
        "import wrds       \n",
        "conn = wrds.Connection() "
      ],
      "metadata": {
        "id": "x2jxPDcZA6vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annual Compustat\n",
        "\n",
        "An example of pulling data from the annual Compustat table.  datadate is the end of the fiscal year.  We impose standard filters.  See https://wrds-web.wharton.upenn.edu/wrds/demo/demoform_compustat.cfm for a full list of Compustat variable definitions. "
      ],
      "metadata": {
        "id": "Qd9Rv1GRM3MT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKo3oYPBJ72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b123ae6-275c-4512-a978-fa6efc5b5d62"
      },
      "source": [
        "variables = ['txditc','pstkrv','pstkl','pstk','ceq','seq','at','lt','cogs','xsga','xint','sale','revt','mib']            \n",
        "\n",
        "start = '1963-01-01'\n",
        "\n",
        "variables = ', '.join(variables)\n",
        "df = conn.raw_sql(             \"SELECT a.gvkey, a.datadate, b.tic,\"\n",
        "                               + variables +\n",
        "                               \" from comp.FUNDA a left outer join comp.Names b \"\n",
        "                               \" on a.gvkey = b.gvkey \"\n",
        "                               \" where a.datadate >= '\" + start + \"' \"\n",
        "                               \" and INDFMT='INDL' and DATAFMT='STD' and POPSRC='D' and CONSOL='C' \"\n",
        "                               \" order by a.gvkey, datadate \", date_cols=['datadate'])\n",
        "df.gvkey = df.gvkey.astype(int)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 526495 entries, 0 to 26494\n",
            "Data columns (total 17 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     526495 non-null  int64         \n",
            " 1   datadate  526495 non-null  datetime64[ns]\n",
            " 2   tic       526340 non-null  object        \n",
            " 3   txditc    411620 non-null  float64       \n",
            " 4   pstkrv    445050 non-null  float64       \n",
            " 5   pstkl     446643 non-null  float64       \n",
            " 6   pstk      449108 non-null  float64       \n",
            " 7   ceq       444379 non-null  float64       \n",
            " 8   seq       442917 non-null  float64       \n",
            " 9   at        448949 non-null  float64       \n",
            " 10  lt        446341 non-null  float64       \n",
            " 11  cogs      445402 non-null  float64       \n",
            " 12  xsga      359266 non-null  float64       \n",
            " 13  xint      400147 non-null  float64       \n",
            " 14  sale      447243 non-null  float64       \n",
            " 15  revt      447245 non-null  float64       \n",
            " 16  mib       432746 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(14), int64(1), object(1)\n",
            "memory usage: 72.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratios and growth rates\n",
        "\n",
        "Illustrate some standard types of calculations with Compustat data by computing some Fama-French characteristics."
      ],
      "metadata": {
        "id": "VwwEaLY1mxjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we shift fiscal-year-end data to the end of June in the next calendar year, to accommodate the reporting lag\n",
        "# this shift is standard for Fama and French\n",
        "\n",
        "df['date'] = pd.to_datetime(df.datadate.apply(lambda d: str(d.year)+'-06-30'))\n",
        "\n",
        "# sometimes a company changes its fiscal year and has two annual reports in the same calendar year\n",
        "# we keep the last annual report in this circumstace\n",
        "\n",
        "df = df.drop_duplicates(subset=['gvkey','date'],keep='last')  \n",
        "\n",
        "# the coalesce function implements the following logic:\n",
        "#   x = a if a exists\n",
        "#   else x = b if b exists\n",
        "#   else x = c if c exists\n",
        "#   ...\n",
        "# the dataframe that is input to the function should have columns in the following order:\n",
        "# first column = a (most desired definition)\n",
        "# second column = b (next most desired definition)\n",
        "# ... last column = least desired definition (used only if others do not exist)\n",
        "\n",
        "def coalesce(d) :\n",
        "    return d.bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "# Fama-French definition of book equity : shareholders equity + deferred taxes - preferred stock\n",
        "# Compustat has three preferred stock variables, we prefer pstkrv, then pstkl, then pstk\n",
        "# we prefer to use seq for shareholders equity, then ceq (common equity) + pstk, then total assets minus total liabilities\n",
        "# when adding pstk to ceq, we allow for pstk to be missing by filling nans with 0\n",
        "# we filter to observations with positive book equity\n",
        "\n",
        "deferredTaxes = df.txditc.fillna(0)    \n",
        "preferredStock = coalesce(df[['pstkrv','pstkl','pstk']]).fillna(0)                  \n",
        "seq2 = df.ceq + df.pstk.fillna(0)                \n",
        "seq3 = np.where((df['at']>=0) & (df['lt']>=0), df['at']-df['lt'], np.nan) \n",
        "seq3 = pd.Series(seq3, index=df.index)\n",
        "shareholdersEquity = coalesce(pd.concat((df.seq,seq2,seq3),axis=1))\n",
        "df['be'] = shareholdersEquity + deferredTaxes - preferredStock\n",
        "df = df[df.be>0]\n",
        "del deferredTaxes, preferredStock, seq2, seq3, shareholdersEquity\n",
        "\n",
        "# Fama-French definition of operating profitability: revenue - cost of goods sold - SG&A expenses - interest expense divided by equity\n",
        "\n",
        "costs = df.cogs.fillna(0) + df.xsga.fillna(0) + df.xint.fillna(0)\n",
        "sales = coalesce(df[['sale','revt']]) \n",
        "df['op'] = (sales-costs) / ( df.be + df.mib.fillna(0) )\n",
        "del costs, sales\n",
        "\n",
        "# Fama-French definition of investment: percent change in assets\n",
        "# we filter to observations with positive total assets\n",
        "# we group by gvkey whenever shifting or calculating changes to avoid errors at the point one firm's data ends and another starts\n",
        "\n",
        "df = df[df['at']>0]\n",
        "df['inv'] = df.groupby('gvkey')['at'].pct_change()\n",
        "\n",
        "# keep the variables we want to use\n",
        "\n",
        "df = df[['gvkey','date','datadate','be','op','inv']]\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "cXwB2fxbQ3kS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fd95c9-0795-4539-b18e-d17f892ac87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 401997 entries, 1 to 26494\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     401997 non-null  int64         \n",
            " 1   date      401997 non-null  datetime64[ns]\n",
            " 2   datadate  401997 non-null  datetime64[ns]\n",
            " 3   be        401997 non-null  float64       \n",
            " 4   op        398891 non-null  float64       \n",
            " 5   inv       368227 non-null  float64       \n",
            "dtypes: datetime64[ns](2), float64(3), int64(1)\n",
            "memory usage: 21.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assign permnos \n",
        "\n",
        "Use the CRSP link table following instructions at WRDS."
      ],
      "metadata": {
        "id": "JRd3YRWgTZYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = conn.raw_sql(\" select distinct gvkey, lpermno as permno, linkdt, linkenddt \"\n",
        "                    \" from crsp.Ccmxpf_linktable \"\n",
        "                    \" where linktype in ('LU', 'LC') \"\n",
        "                    \" and LINKPRIM in ('P', 'C') \" )\n",
        "link['gvkey'] = link.gvkey.astype(int)\n",
        "link['permno'] = link.permno.astype(int)\n",
        "link['linkenddt'] = pd.to_datetime(link.linkenddt).fillna(pd.Timestamp('21000101'))\n",
        "df = df.merge(link,on='gvkey',how='inner')\n",
        "df = df[(df.datadate>=df.linkdt) & (df.datadate<=df.linkenddt)]\n",
        "df = df.drop(columns=['gvkey','datadate','linkdt','linkenddt'])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "5GwgshZLTVRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af44ce38-4eae-4c38-c4cd-c3814c622d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 274402 entries, 6 to 407280\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype         \n",
            "---  ------  --------------   -----         \n",
            " 0   date    274402 non-null  datetime64[ns]\n",
            " 1   be      274402 non-null  float64       \n",
            " 2   op      273171 non-null  float64       \n",
            " 3   inv     264085 non-null  float64       \n",
            " 4   permno  274402 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
            "memory usage: 12.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRSP\n",
        "\n",
        "Get stock prices and returns from  CRSP (Center for Research in Security Prices).  There is both monthly and daily data.  See http://www.crsp.com/files/data_descriptions_guide_0.pdf for a complete set of variable definitions.  CRSP uses PERMCO as a permanent company identifier and PERMNO as a permanent security identifier.  Some companies have multiple classes of common stock, which means multiple common stock PERMNOs can be associated with a single PERMCO."
      ],
      "metadata": {
        "id": "X1bNXUw6T4xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = 'monthly'\n",
        "start = '1962-01-01'\n",
        "crsp_table = 'msf' if freq=='monthly' else 'dsf'\n",
        "     \n",
        "df2 = conn.raw_sql(\"SELECT a.permno, a.permco, a.date, a.ret, abs(a.prc)*a.shrout as me, b.exchcd, b.siccd, b.ticker \"\n",
        "                   \" from crsp.\" + crsp_table + \" a inner join crsp.msenames b \"\n",
        "                   \" on a.permno=b.permno and a.date between b.namedt and b.nameendt \"\n",
        "                   \" and b.exchcd in (1,2,3) and b.shrcd in (10,11) \"\n",
        "                   \" where a.date >= '\" + start + \"' \"\n",
        "                   \" order by a.date, a.permco, me \", date_cols=['date'])\n",
        "\n",
        "for col in ['permno','permco','exchcd'] :\n",
        "    df2[col] = df2[col].astype(int)\n",
        "\n",
        "# define market equity as sum of market equities of all permnos associated with a permco\n",
        "df2['me'] = df2.groupby(['date','permco']).me.transform(sum)\n",
        "\n",
        "# if there are multiple permnos for a permco, keep only the permno with largest market equity\n",
        "# this works because the sql query sorted by market equity within date/permco\n",
        "df2 = df2.drop_duplicates(subset=['date','permco'],keep='last')\n",
        "df2 = df2.drop(columns=['permco'])\n",
        "\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "VP7s-_6FRglI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c215f2b-ca59-4fc1-85fe-4272847b6aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257644 entries, 0 to 291289\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(2), object(1)\n",
            "memory usage: 198.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define delisting returns\n",
        "\n",
        "This is always done, but there are some different ways to do it.  Here, we follow some of the literature and assign a lower delisting return to Nasdaq stocks than to NYSE/AMEX stocks if the delisting return is missing."
      ],
      "metadata": {
        "id": "9mCTmtbQQLVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = conn.raw_sql(\" select permno, dlret, dlstcd \" \n",
        "                   \" from crsp.mse \" \n",
        "                   \" where event='DELIST' and dlstcd>100 \"\n",
        "                   \" order by permno\")\n",
        "mse['permno'] = mse.permno.astype(int)\n",
        "df2 = df2.merge(mse, how='left', on='permno')\n",
        "del mse\n",
        "LastObs = df2.permno != df2.permno.shift(-1)                           # True if last date for stock\n",
        "DLCode = (df2.dlstcd==500) | ( (df2.dlstcd >=520)&(df2.dlstcd<=584) )  # True if delisted for poor performance\n",
        "\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & df2.exchcd.isin([1,2]), -0.35, df2.dlret )\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & (df2.exchcd==3), -0.55, df2.dlret )\n",
        "df2['dlret'] = np.where(df2.dlret.notnull() & df2.dlret<-1,-1,df2.dlret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.notnull(), (1+df2.ret)*(1+df2.dlret.fillna(0))-1, df2.ret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.isnull(), df2.dlret, df2.ret)\n",
        "df2 = df2.drop(columns=['dlstcd','dlret'])"
      ],
      "metadata": {
        "id": "hbc9Cedj56hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge CRSP with Compustat"
      ],
      "metadata": {
        "id": "Ot2qAYgwQyWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df2.merge(df, on = ['permno','date'], how='left')\n",
        "df.sort_values(by=['permno','date'],inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7c2-JEJvuv",
        "outputId": "dd0f3968-4a8f-4199-9bf6-c8577b41ebe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257652 entries, 1066070 to 3255330\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            " 7   be      float64       \n",
            " 8   op      float64       \n",
            " 9   inv     float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(2), object(1)\n",
            "memory usage: 273.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define size and book-to-market\n",
        "\n",
        "Fama and French use end-of-June market cap to define size each year (as of June 30).  They use end-of-prior-December market cap to define book-to-market on June 30.  "
      ],
      "metadata": {
        "id": "Oj6cH-wCY8qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "month = df.date.apply(lambda d: d.month)\n",
        "df['size'] = np.where(month==6, df.me, np.nan)\n",
        "df['bm'] = df.groupby('permno').apply(lambda d: d.be/d.me.shift(6)).values\n",
        "df['bm'] = np.where(month==6, df.bm, np.nan)\n",
        "df = df.drop(columns=['be'])"
      ],
      "metadata": {
        "id": "dtBuGlYqZH2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill annual data into months\n",
        "\n",
        "Use the pandas ffill method to fill forward from Junes into successive months.  Occasionally firms change fiscal years, so filling for more than 12 months can be useful.  On the other hand, we don't want to fill forward if a permno exits the database for years and then returns, which happens occasionally (though rarely).  18 months is my arbitrary compromise."
      ],
      "metadata": {
        "id": "mKNaAI0pURK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['size','bm','op','inv']] = df.groupby('permno')[['size','bm','op','inv']].ffill(limit=18)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "353HWR6OKa4Q",
        "outputId": "03f447e5-22b8-4bce-cbbf-2f80e330fb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3257652 entries, 1066070 to 3255330\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   date    datetime64[ns]\n",
            " 2   ret     float64       \n",
            " 3   me      float64       \n",
            " 4   exchcd  int64         \n",
            " 5   siccd   float64       \n",
            " 6   ticker  object        \n",
            " 7   op      float64       \n",
            " 8   inv     float64       \n",
            " 9   size    float64       \n",
            " 10  bm      float64       \n",
            "dtypes: datetime64[ns](1), float64(7), int64(2), object(1)\n",
            "memory usage: 298.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmhA0_owBJ8R"
      },
      "source": [
        "## Close WRDS\n",
        "\n",
        "You should close your WRDS connection when you are finished with it.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmQYRd0rBJ8T"
      },
      "source": [
        "conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fweL1rPCBJ8e"
      },
      "source": [
        "## Save Your Data\n",
        "\n",
        "The write and read commands to csv are as follows.  Here, we mount and save to google drive.\n",
        "\n",
        "    df.to_csv('/path/filename.csv')                                      # writes to disk  \n",
        "    df = pd.read_csv('/path/filename.csv', date_cols=['date'])           # reads from disk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLq29beCBJ8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804e584d-e361-48c1-d50a-5f7e5fa9b212"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df.to_csv('/content/drive/My Drive/crsp_compustat_example.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G8Ut-5xipF_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}