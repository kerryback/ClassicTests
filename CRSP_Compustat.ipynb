{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "CRSP_Compustat.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerryback/WRDS/blob/main/CRSP_Compustat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ],
      "metadata": {
        "id": "9ZAhurdxGkCk",
        "outputId": "b846639e-285e-40f6-e22f-136af64f6736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and connect to WRDS"
      ],
      "metadata": {
        "id": "_LoCzT5GBd5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install wrds\n",
        "import wrds       \n",
        "conn = wrds.Connection() "
      ],
      "metadata": {
        "id": "x2jxPDcZA6vM",
        "outputId": "36b14209-6600-4a1a-811f-d50c334e004e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from wrds) (1.4.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from wrds) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from wrds) (1.3.5)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->wrds) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->wrds) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->wrds) (4.11.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->wrds) (1.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->wrds) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->wrds) (3.10.0.2)\n",
            "Installing collected packages: psycopg2-binary, mock, wrds\n",
            "Successfully installed mock-4.0.3 psycopg2-binary-2.9.3 wrds-3.1.1\n",
            "Enter your WRDS username [root]:keback\n",
            "Enter your password:··········\n",
            "WRDS recommends setting up a .pgpass file.\n",
            "Create .pgpass file now [y/n]?: n\n",
            "You can create this file yourself at any time\n",
            "with the create_pgpass_file() function.\n",
            "Loading library list...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annual Compustat\n",
        "\n",
        "An example of pulling data from the annual Compustat table.  datadate is the end of the fiscal year.  We impose standard filters.  See https://wrds-web.wharton.upenn.edu/wrds/demo/demoform_compustat.cfm for a full list of Compustat variable definitions. Quarterly data is also available."
      ],
      "metadata": {
        "id": "Qd9Rv1GRM3MT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKo3oYPBJ72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10646461-d880-4f67-bd40-45e77654f23c"
      },
      "source": [
        "variables = ['txditc','pstkrv','pstkl','pstk','ceq','seq','at','lt','cogs','xsga','xint','sale','revt','mib']            \n",
        "\n",
        "start = '1963-01-01'\n",
        "\n",
        "variables = ', '.join(variables)\n",
        "df = conn.raw_sql(             \"SELECT a.gvkey, a.datadate, b.tic,\"\n",
        "                               + variables +\n",
        "                               \" from comp.FUNDA a left outer join comp.Names b \"\n",
        "                               \" on a.gvkey = b.gvkey \"\n",
        "                               \" where a.datadate >= '\" + start + \"' \"\n",
        "                               \" and INDFMT='INDL' and DATAFMT='STD' and POPSRC='D' and CONSOL='C' \"\n",
        "                               \" order by a.gvkey, datadate \", date_cols=['datadate'])\n",
        "df.gvkey = df.gvkey.astype(int)\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 526750 entries, 0 to 26749\n",
            "Data columns (total 17 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     526750 non-null  int64         \n",
            " 1   datadate  526750 non-null  datetime64[ns]\n",
            " 2   tic       526595 non-null  object        \n",
            " 3   txditc    411873 non-null  float64       \n",
            " 4   pstkrv    445356 non-null  float64       \n",
            " 5   pstkl     446954 non-null  float64       \n",
            " 6   pstk      449381 non-null  float64       \n",
            " 7   ceq       444652 non-null  float64       \n",
            " 8   seq       443187 non-null  float64       \n",
            " 9   at        449220 non-null  float64       \n",
            " 10  lt        446608 non-null  float64       \n",
            " 11  cogs      445674 non-null  float64       \n",
            " 12  xsga      359485 non-null  float64       \n",
            " 13  xint      400394 non-null  float64       \n",
            " 14  sale      447515 non-null  float64       \n",
            " 15  revt      447517 non-null  float64       \n",
            " 16  mib       433017 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(14), int64(1), object(1)\n",
            "memory usage: 72.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratios and growth rates\n",
        "\n",
        "Illustrate some standard types of calculations with Compustat data by computing some Fama-French characteristics."
      ],
      "metadata": {
        "id": "VwwEaLY1mxjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we shift fiscal-year-end data to the end of June in the next calendar year, to accommodate the reporting lag\n",
        "# this shift is standard for Fama and French\n",
        "\n",
        "df['date'] = pd.to_datetime(df.datadate.apply(lambda d: str(d.year+1)+'-06-30'))\n",
        "\n",
        "# sometimes a company changes its fiscal year and has two annual reports in the same calendar year\n",
        "# we keep the last annual report in this circumstace\n",
        "\n",
        "df = df.drop_duplicates(subset=['gvkey','date'],keep='last')  \n",
        "\n",
        "# the coalesce function implements the following logic:\n",
        "#   x = a if a exists\n",
        "#   else x = b if b exists\n",
        "#   else x = c if c exists\n",
        "#   ...\n",
        "# the dataframe that is input to the function should have columns in the following order:\n",
        "# first column = a (most desired definition)\n",
        "# second column = b (next most desired definition)\n",
        "# ... last column = least desired definition (used only if others do not exist)\n",
        "\n",
        "def coalesce(d) :\n",
        "    return d.bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "# Fama-French definition of book equity : shareholders equity + deferred taxes - preferred stock\n",
        "# Compustat has three preferred stock variables, we prefer pstkrv, then pstkl, then pstk\n",
        "# we prefer to use seq for shareholders equity, then ceq (common equity) + pstk, then total assets minus total liabilities\n",
        "# when adding pstk to ceq, we allow for pstk to be missing by filling nans with 0\n",
        "# we filter to observations with positive book equity\n",
        "\n",
        "deferredTaxes = df.txditc.fillna(0)    \n",
        "preferredStock = coalesce(df[['pstkrv','pstkl','pstk']]).fillna(0)                  \n",
        "seq2 = df.ceq + df.pstk.fillna(0)                \n",
        "seq3 = np.where((df['at']>=0) & (df['lt']>=0), df['at']-df['lt'], np.nan) \n",
        "seq3 = pd.Series(seq3, index=df.index)\n",
        "shareholdersEquity = coalesce(pd.concat((df.seq,seq2,seq3),axis=1))\n",
        "df['be'] = shareholdersEquity + deferredTaxes - preferredStock\n",
        "df = df[df.be>0]\n",
        "del deferredTaxes, preferredStock, seq2, seq3, shareholdersEquity\n",
        "\n",
        "# Fama-French definition of operating profitability: revenue - cost of goods sold - SG&A expenses - interest expense divided by equity\n",
        "\n",
        "costs = df.cogs.fillna(0) + df.xsga.fillna(0) + df.xint.fillna(0)\n",
        "sales = coalesce(df[['sale','revt']]) \n",
        "df['op'] = (sales-costs) / ( df.be + df.mib.fillna(0) )\n",
        "del costs, sales\n",
        "\n",
        "# Fama-French definition of investment: percent change in assets\n",
        "# we filter to observations with positive total assets\n",
        "# we group by gvkey whenever shifting or calculating changes to avoid errors at the point one firm's data ends and another starts\n",
        "\n",
        "df = df[df['at']>0]\n",
        "df['inv'] = df.groupby('gvkey')['at'].pct_change()\n",
        "\n",
        "# keep the variables we want to use\n",
        "\n",
        "df = df[['gvkey','date','datadate','be','op','inv']]\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "cXwB2fxbQ3kS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c591b21-8f42-479f-ae56-5bf8a9452765"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 402245 entries, 1 to 26749\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   gvkey     402245 non-null  int64         \n",
            " 1   date      402245 non-null  datetime64[ns]\n",
            " 2   datadate  402245 non-null  datetime64[ns]\n",
            " 3   be        402245 non-null  float64       \n",
            " 4   op        399140 non-null  float64       \n",
            " 5   inv       368463 non-null  float64       \n",
            "dtypes: datetime64[ns](2), float64(3), int64(1)\n",
            "memory usage: 21.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assign permnos \n",
        "\n",
        "Use the CRSP link table following instructions at WRDS."
      ],
      "metadata": {
        "id": "JRd3YRWgTZYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = conn.raw_sql(\" select distinct gvkey, lpermno as permno, linkdt, linkenddt \"\n",
        "                    \" from crsp.Ccmxpf_linktable \"\n",
        "                    \" where linktype in ('LU', 'LC') \"\n",
        "                    \" and LINKPRIM in ('P', 'C') \" )\n",
        "link['gvkey'] = link.gvkey.astype(int)\n",
        "link['permno'] = link.permno.astype(int)\n",
        "link['linkenddt'] = pd.to_datetime(link.linkenddt).fillna(pd.Timestamp('21000101'))\n",
        "df = df.merge(link,on='gvkey',how='inner')\n",
        "df = df[(df.datadate>=df.linkdt) & (df.datadate<=df.linkenddt)]\n",
        "df = df.drop(columns=['gvkey','datadate','linkdt','linkenddt'])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "5GwgshZLTVRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de98dde-5031-42ae-f5ca-9d56bf9d9695"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 274615 entries, 6 to 407520\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype         \n",
            "---  ------  --------------   -----         \n",
            " 0   date    274615 non-null  datetime64[ns]\n",
            " 1   be      274615 non-null  float64       \n",
            " 2   op      273385 non-null  float64       \n",
            " 3   inv     264288 non-null  float64       \n",
            " 4   permno  274615 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
            "memory usage: 12.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRSP\n",
        "\n",
        "Get stock prices and returns from  CRSP (Center for Research in Security Prices).  There is both monthly and daily data.  See http://www.crsp.com/files/data_descriptions_guide_0.pdf for a complete set of variable definitions.  CRSP uses PERMCO as a permanent company identifier and PERMNO as a permanent security identifier.  Some companies have multiple classes of common stock, which means multiple common stock PERMNOs can be associated with a single PERMCO."
      ],
      "metadata": {
        "id": "X1bNXUw6T4xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = 'monthly'\n",
        "start = '1962-01-01'\n",
        "crsp_table = 'msf' if freq=='monthly' else 'dsf'\n",
        "     \n",
        "df2 = conn.raw_sql(\"SELECT a.permno, a.permco, a.date, a.ret, abs(a.prc)*a.shrout as me, b.exchcd, b.siccd, b.ticker \"\n",
        "                   \" from crsp.\" + crsp_table + \" a inner join crsp.msenames b \"\n",
        "                   \" on a.permno=b.permno and a.date between b.namedt and b.nameendt \"\n",
        "                   \" and b.exchcd in (1,2,3) and b.shrcd in (10,11) \"\n",
        "                   \" where a.date >= '\" + start + \"' \"\n",
        "                   \" order by a.permno, a.date \", date_cols=['date'])\n",
        "\n",
        "for col in ['permno','permco','exchcd'] :\n",
        "    df2[col] = df2[col].astype(int)\n",
        "\n",
        "# define market equity as sum of market equities of all permnos associated with a permco\n",
        "df2['me'] = df2.groupby(['date','permco']).me.transform(sum)\n",
        "\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "VP7s-_6FRglI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd3ad58-7f9c-4c19-f3a0-142d574ec237"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3291290 entries, 0 to 291289\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   permco  int64         \n",
            " 2   date    datetime64[ns]\n",
            " 3   ret     float64       \n",
            " 4   me      float64       \n",
            " 5   exchcd  int64         \n",
            " 6   siccd   float64       \n",
            " 7   ticker  object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(3), object(1)\n",
            "memory usage: 226.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define delisting returns\n",
        "\n",
        "This is always done, but there are some different ways to do it.  Here, we follow some of the literature and assign a lower delisting return to Nasdaq stocks than to NYSE/AMEX stocks if the delisting return is missing."
      ],
      "metadata": {
        "id": "9mCTmtbQQLVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = conn.raw_sql(\" select permno, dlret, dlstcd \" \n",
        "                   \" from crsp.mse \" \n",
        "                   \" where event='DELIST' and dlstcd>100 \"\n",
        "                   \" order by permno\")\n",
        "mse['permno'] = mse.permno.astype(int)\n",
        "df2 = df2.merge(mse, how='left', on='permno')\n",
        "del mse\n",
        "LastObs = df2.permno != df2.permno.shift(-1)                           # True if last date for stock\n",
        "DLCode = (df2.dlstcd==500) | ( (df2.dlstcd >=520)&(df2.dlstcd<=584) )  # True if delisted for poor performance\n",
        "\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & df2.exchcd.isin([1,2]), -0.35, df2.dlret )\n",
        "df2['dlret'] = np.where(DLCode & df2.dlret.isnull() & (df2.exchcd==3), -0.55, df2.dlret )\n",
        "df2['dlret'] = np.where(df2.dlret.notnull() & df2.dlret<-1,-1,df2.dlret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.notnull(), (1+df2.ret)*(1+df2.dlret.fillna(0))-1, df2.ret)\n",
        "df2['ret'] = np.where(LastObs & df2.ret.isnull(), df2.dlret, df2.ret)\n",
        "df2 = df2.drop(columns=['dlstcd','dlret'])"
      ],
      "metadata": {
        "id": "hbc9Cedj56hg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Close WRDS\n",
        "\n",
        "You should close your WRDS connection when you have the data you need."
      ],
      "metadata": {
        "id": "andSngk7dYYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "IG450QBedW-q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge CRSP with Compustat"
      ],
      "metadata": {
        "id": "Ot2qAYgwQyWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df2.merge(df, on = ['permno','date'], how='left')\n",
        "df.sort_values(by=['permno','date'],inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7c2-JEJvuv",
        "outputId": "8505cfca-9224-4da4-af05-43352aec18c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3291301 entries, 0 to 3291300\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   permco  int64         \n",
            " 2   date    datetime64[ns]\n",
            " 3   ret     float64       \n",
            " 4   me      float64       \n",
            " 5   exchcd  int64         \n",
            " 6   siccd   float64       \n",
            " 7   ticker  object        \n",
            " 8   be      float64       \n",
            " 9   op      float64       \n",
            " 10  inv     float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(3), object(1)\n",
            "memory usage: 301.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define size and book-to-market\n",
        "\n",
        "Fama and French use end-of-June market cap to define size each year (as of June 30).  They use end-of-prior-December market cap to define book-to-market on June 30.  "
      ],
      "metadata": {
        "id": "Oj6cH-wCY8qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "month = df.date.apply(lambda d: d.month)\n",
        "df['size'] = np.where(month==6, df.me, np.nan)\n",
        "df['bm'] = df.groupby('permno').apply(lambda d: d.be/d.me.shift(6)).values\n",
        "df['bm'] = np.where(month==6, df.bm, np.nan)\n",
        "df = df.drop(columns=['be'])"
      ],
      "metadata": {
        "id": "dtBuGlYqZH2V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill annual data into months\n",
        "\n",
        "Use the pandas ffill method to fill forward from Junes into the following July, Aug, ..., May."
      ],
      "metadata": {
        "id": "mKNaAI0pURK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['size','bm','op','inv']] = df.groupby('permno')[['size','bm','op','inv']].ffill(limit=11)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "353HWR6OKa4Q",
        "outputId": "98a293a6-3b14-4f3b-a9c4-3accf73c8eff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3291301 entries, 0 to 3291300\n",
            "Data columns (total 12 columns):\n",
            " #   Column  Dtype         \n",
            "---  ------  -----         \n",
            " 0   permno  int64         \n",
            " 1   permco  int64         \n",
            " 2   date    datetime64[ns]\n",
            " 3   ret     float64       \n",
            " 4   me      float64       \n",
            " 5   exchcd  int64         \n",
            " 6   siccd   float64       \n",
            " 7   ticker  object        \n",
            " 8   op      float64       \n",
            " 9   inv     float64       \n",
            " 10  size    float64       \n",
            " 11  bm      float64       \n",
            "dtypes: datetime64[ns](1), float64(7), int64(3), object(1)\n",
            "memory usage: 326.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lag monthly characteristics.\n",
        "\n",
        "Lag characteristics, so they are all known at the beginning of each month."
      ],
      "metadata": {
        "id": "EQfSCMdp6idm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['size','bm','op','inv','me'] :\n",
        "  df[col] = df.groupby('permno')[col].shift()"
      ],
      "metadata": {
        "id": "Ys6jOHqL6hkM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fweL1rPCBJ8e"
      },
      "source": [
        "## Save Your Data\n",
        "\n",
        "Mount google drive and save."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLq29beCBJ8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81810423-c8a2-46cc-8d25-b0c720a7ac63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df.to_csv('/content/drive/My Drive/crsp_compustat_example.csv')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}